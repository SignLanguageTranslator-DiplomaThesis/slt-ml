import copy

import cv2 as cv
import mediapipe as mp

from constants import constants
from csv_parser.csv_parser import CsvParser
from interface.interface import UserInterface
from interface.annotations import Annotations
from model.sign_classifier.classifier import SignClassifier


def main():
    # Camera preparation
    cap = cv.VideoCapture(constants.WEBCAM_DEVICE_INPUT)
    cap.set(cv.CAP_PROP_FRAME_WIDTH, constants.CAPTURE_FRAME_WIDTH)
    cap.set(cv.CAP_PROP_FRAME_HEIGHT, constants.CAPTURE_FRAME_HEIGHT)

    # Model load
    mp_hands = mp.solutions.hands
    hands = mp_hands.Hands(
        static_image_mode=constants.USE_STATIC_IMAGE_MODE,
        max_num_hands=constants.MAX_NUMBER_OF_HANDS,
        min_detection_confidence=constants.MIN_DETECTION_CONFIDENCE,
        min_tracking_confidence=constants.MIN_TRACKING_CONFIDENCE,
    )

    sign_gesture_classifier = SignClassifier()

    # Read labels from sign_classifier_label CSV file
    sign_language_labels = CsvParser.read_sign_labels()

    number = constants.NOT_SELECTED

    while cap.isOpened():
        key = cv.waitKey(10)
        if key == constants.ESC_KEY:
            break
        number, mode = select_mode(key, number, sign_language_labels)

        # Camera capture
        success, image = cap.read()
        if not success:
            print("Ignoring empty camera frame.")
            break

        image = cv.flip(image, 1)  # Mirror display
        edit_image = copy.deepcopy(image)

        # Detection implementation
        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)

        image.flags.writeable = False
        results = hands.process(image)
        image.flags.writeable = True

        if results.multi_hand_landmarks:
            for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):
                # Landmark calculation
                landmark_list = get_pixel_coord_landmarks(edit_image, hand_landmarks)

                # Bounding box calculation
                bounding_box = Annotations.compute_bounding_box(landmark_list)

                # Conversion to relative, normalized coordinates
                normalized_landmarks = get_normalized_coord_landmarks(landmark_list)

                # Write to the dataset file
                CsvParser.logging_csv(mode, number, normalized_landmarks)

                # Hand sign classification
                sign_gesture_index = sign_gesture_classifier.classify(normalized_landmarks)

                # Draws the 21 landmark points generated by MediaPipe and the lines connecting them
                edit_image = Annotations.draw_landmarks(edit_image, results.multi_hand_landmarks)

                edit_image = Annotations.draw_info_text(
                    edit_image,
                    bounding_box,
                    handedness,
                    sign_language_labels[sign_gesture_index]
                )

        edit_image = Annotations.draw_info(edit_image, mode)

        # Screen reflection
        cv.imshow('Sign Language Translator', edit_image)

    cap.release()
    cv.destroyAllWindows()


def select_mode(key, number, sign_language_labels):
    user_interface = UserInterface()
    mode = constants.NOT_SELECTED
    if key == constants.CHOOSE_LABEL_MODE:
        user_interface.generate_label_dropdown(sign_language_labels)
        number = user_interface.selected_label_index
    elif key == constants.CREATE_LABEL_MODE:
        user_interface.generate_input_field(sign_language_labels)
    if key in constants.modes:
        mode = key
    return number, mode


def get_pixel_coord_landmarks(image, landmarks):
    image_height, image_width, _ = image.shape

    pixel_landmarks = []

    # Iterate through each landmark point
    for landmark in landmarks.landmark:
        # Convert landmark coordinates from normalized [0, 1] to pixel coordinates
        landmark_x = int(landmark.x * image_width)
        landmark_y = int(landmark.y * image_height)

        # Append the pixel coordinates to the landmark list
        pixel_landmarks.append([landmark_x, landmark_y])

    return pixel_landmarks


def get_normalized_coord_landmarks(landmarks):
    normalized_landmarks = []

    min_landmark_x = min(landmarks, key=lambda landmark: landmark[0])[0]
    min_landmark_y = min(landmarks, key=lambda landmark: landmark[1])[1]

    max_landmark_x = max(landmarks, key=lambda landmark: landmark[0])[0]
    max_landmark_y = max(landmarks, key=lambda landmark: landmark[1])[1]

    # Calculate the range of x and y values
    x_range = max_landmark_x - min_landmark_x
    y_range = max_landmark_y - min_landmark_y

    # Convert to relative coordinates and normalize
    for landmark_point in landmarks:
        x, y = landmark_point
        relative_x = (x - min_landmark_x) / x_range
        relative_y = (y - min_landmark_y) / y_range
        normalized_landmarks.extend([relative_x, relative_y])

    return normalized_landmarks


if __name__ == '__main__':
    main()
