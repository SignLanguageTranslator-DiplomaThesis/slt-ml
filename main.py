import copy

import cv2 as cv
import mediapipe as mp

from model import SignClassifier
from model.sign_classifier import constants
from csv_parser.csv_parser import CsvParser
from interface.interface import UserInterface
from interface.annotations import Annotations


def main():
    # Camera preparation
    cap = cv.VideoCapture(constants.WEBCAM_DEVICE_INPUT)
    cap.set(cv.CAP_PROP_FRAME_WIDTH, constants.CAPTURE_FRAME_WIDTH)
    cap.set(cv.CAP_PROP_FRAME_HEIGHT, constants.CAPTURE_FRAME_HEIGHT)

    # Model load
    mp_hands = mp.solutions.hands
    hands = mp_hands.Hands(
        static_image_mode=constants.USE_STATIC_IMAGE_MODE,
        max_num_hands=constants.MAX_NUMBER_OF_HANDS,
        min_detection_confidence=constants.MIN_DETECTION_CONFIDENCE,
        min_tracking_confidence=constants.MIN_TRACKING_CONFIDENCE,
    )

    sign_classifier = SignClassifier()

    # Read labels from sign_classifier_label CSV file
    sign_language_labels = CsvParser.read_sign_labels()

    number = -1

    while cap.isOpened():
        key = cv.waitKey(10)
        if key == 27:  # ESC
            break
        number, mode = select_mode(key, number, sign_language_labels)

        # Camera capture
        success, image = cap.read()
        if not success:
            print("Ignoring empty camera frame.")
            break

        image = cv.flip(image, 1)  # Mirror display
        debug_image = copy.deepcopy(image)

        # Detection implementation
        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)

        image.flags.writeable = False
        results = hands.process(image)
        image.flags.writeable = True

        if results.multi_hand_landmarks:
            for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):
                # Bounding box calculation
                brect = Annotations.calc_bounding_rect(debug_image, hand_landmarks)

                # Landmark calculation
                landmark_list = get_pixel_coord_landmark_list(debug_image, hand_landmarks)

                # Conversion to relative coordinates / normalized coordinates
                normalized_landmarks = normalize_landmarks(landmark_list)

                # Write to the dataset file
                CsvParser.logging_csv(mode, number, normalized_landmarks)

                # Hand sign classification
                hand_sign_id = sign_classifier.classify(normalized_landmarks)

                # DF: draws the 21 landmark points generated by MediaPipe and the lines connecting them
                debug_image = Annotations.draw_landmarks(debug_image, results.multi_hand_landmarks)

                debug_image = Annotations.draw_info_text(
                    debug_image,
                    brect,
                    handedness,
                    sign_language_labels[hand_sign_id]
                )

        debug_image = Annotations.draw_info(debug_image, mode)

        # Screen reflection
        cv.imshow('Sign Language Translator', debug_image)

    cap.release()
    cv.destroyAllWindows()


def select_mode(key, number, sign_language_labels):
    user_interface = UserInterface()
    mode = -1
    if key == 110:  # n - normal mode
        mode = 0
    elif key == 107:  # k - save new data in the dataset
        mode = 1
    elif key == 115:  # s - choose sign gesture (label) to perform
        user_interface.generate_label_dropdown(sign_language_labels)
        number = user_interface.selected_label_index
        mode = 2
        print(number)
    elif key == 108:  # l - save new label in the CSV file
        user_interface.generate_input_field(sign_language_labels)
        mode = 3
    return number, mode


def get_pixel_coord_landmark_list(image, landmarks):
    image_height, image_width, _ = image.shape

    landmark_list = []

    # Iterate through each landmark point
    for landmark in landmarks.landmark:
        # Convert landmark coordinates from normalized [0, 1] to pixel coordinates
        landmark_x = int(landmark.x * image_width)
        landmark_y = int(landmark.y * image_height)

        # Append the pixel coordinates to the landmark list
        landmark_list.append([landmark_x, landmark_y])

    return landmark_list


def normalize_landmarks(landmark_list):
    normalized_landmarks = []

    min_landmark_x = min(landmark_list, key=lambda landmark: landmark[0])[0]
    min_landmark_y = min(landmark_list, key=lambda landmark: landmark[1])[1]

    max_landmark_x = max(landmark_list, key=lambda landmark: landmark[0])[0]
    max_landmark_y = max(landmark_list, key=lambda landmark: landmark[1])[1]

    # Calculate the range of x and y values
    x_range = max_landmark_x - min_landmark_x
    y_range = max_landmark_y - min_landmark_y

    # Convert to relative coordinates and normalize
    for landmark_point in landmark_list:
        x, y = landmark_point
        relative_x = (x - min_landmark_x) / x_range
        relative_y = (y - min_landmark_y) / y_range
        normalized_landmarks.extend([relative_x, relative_y])

    return normalized_landmarks


if __name__ == '__main__':
    main()
